{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 - Exploring Neural Network Architectures for Advancing and Predicting Chaotic Dynamics in the Lorenz System\n",
    "# Github: https://github.com/idane2309 | Ishan Dane"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Train a NN to advance the solution from t to t + ∆t for ρ = 10, 28 and 40. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from scipy import integrate\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test values for rho\n",
    "rho_train_values = [10, 28, 40]\n",
    "rho_test_values = [17, 35]\n",
    "\n",
    "def get_lorenz_deriv(rho):\n",
    "    # Initialize parameters\n",
    "    dt = 0.01\n",
    "    T = 8\n",
    "    t = np.arange(0,T+dt,dt)\n",
    "    beta = 8/3\n",
    "    sigma = 10\n",
    "\n",
    "    # Initialize input and output arrays for rho value\n",
    "    nn_input = np.zeros((100 * (len(t) - 1), 3))\n",
    "    nn_output = np.zeros_like(nn_input)\n",
    "\n",
    "    # Define Lorenz system\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "    \n",
    "    # Solve Lorenz system for rho value\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                    for x0_j in x0])\n",
    "\n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "    \n",
    "    return nn_input, nn_output\n",
    "\n",
    "def create_train_data(rho_train_values):\n",
    "    # Initialize input and output arrays\n",
    "    nn_input = np.zeros((0, 3))\n",
    "    nn_output = np.zeros_like(nn_input)\n",
    "\n",
    "    # Get training data for each rho value\n",
    "    for rho in rho_train_values:\n",
    "        nn_input_rho, nn_output_rho = get_lorenz_deriv(rho)\n",
    "        nn_input = np.concatenate((nn_input, nn_input_rho))\n",
    "        nn_output = np.concatenate((nn_output, nn_output_rho))\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    nn_input = torch.from_numpy(nn_input).float()\n",
    "    nn_output = torch.from_numpy(nn_output).float()\n",
    "\n",
    "    return nn_input, nn_output\n",
    "\n",
    "def create_test_data(rho):\n",
    "    nn_test_input, nn_test_output = get_lorenz_deriv(rho)\n",
    "    nn_test_input = torch.from_numpy(nn_test_input).float()\n",
    "    nn_test_output = torch.from_numpy(nn_test_output).float()\n",
    "\n",
    "    return nn_test_input, nn_test_output\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  290.7338562011719\n",
      "Epoch:  1 Loss:  268.8385925292969\n",
      "Epoch:  2 Loss:  248.95135498046875\n",
      "Epoch:  3 Loss:  231.1382293701172\n",
      "Epoch:  4 Loss:  215.1306610107422\n",
      "Epoch:  5 Loss:  200.9007110595703\n",
      "Epoch:  6 Loss:  188.52249145507812\n",
      "Epoch:  7 Loss:  177.84596252441406\n",
      "Epoch:  8 Loss:  168.62496948242188\n",
      "Epoch:  9 Loss:  160.67105102539062\n",
      "Epoch:  10 Loss:  153.8308563232422\n",
      "Epoch:  11 Loss:  147.9592742919922\n",
      "Epoch:  12 Loss:  142.92112731933594\n",
      "Epoch:  13 Loss:  138.59544372558594\n",
      "Epoch:  14 Loss:  134.87747192382812\n",
      "Epoch:  15 Loss:  131.67799377441406\n",
      "Epoch:  16 Loss:  128.92086791992188\n",
      "Epoch:  17 Loss:  126.54083251953125\n",
      "Epoch:  18 Loss:  124.48184204101562\n",
      "Epoch:  19 Loss:  122.69554138183594\n",
      "Epoch:  20 Loss:  121.14019775390625\n",
      "Epoch:  21 Loss:  119.7796630859375\n",
      "Epoch:  22 Loss:  118.5826644897461\n",
      "Epoch:  23 Loss:  117.52207946777344\n",
      "Epoch:  24 Loss:  116.57438659667969\n",
      "Epoch:  25 Loss:  115.71939086914062\n",
      "Epoch:  26 Loss:  114.93975830078125\n",
      "Epoch:  27 Loss:  114.22086334228516\n",
      "Epoch:  28 Loss:  113.55007934570312\n",
      "Epoch:  29 Loss:  112.91604614257812\n",
      "Epoch:  30 Loss:  112.30848693847656\n",
      "Epoch:  31 Loss:  111.71810913085938\n",
      "Epoch:  32 Loss:  111.13626861572266\n",
      "Epoch:  33 Loss:  110.55406951904297\n",
      "Epoch:  34 Loss:  109.96073150634766\n",
      "Epoch:  35 Loss:  109.34004211425781\n",
      "Epoch:  36 Loss:  108.66343688964844\n",
      "Epoch:  37 Loss:  107.88240051269531\n",
      "Epoch:  38 Loss:  107.00080108642578\n",
      "Epoch:  39 Loss:  106.3836441040039\n",
      "Epoch:  40 Loss:  105.90193176269531\n",
      "Epoch:  41 Loss:  105.489501953125\n",
      "Epoch:  42 Loss:  106.18673706054688\n",
      "Epoch:  43 Loss:  104.51568603515625\n",
      "Epoch:  44 Loss:  104.2119369506836\n",
      "Epoch:  45 Loss:  104.06269073486328\n",
      "Epoch:  46 Loss:  106.6167984008789\n",
      "Epoch:  47 Loss:  104.34373474121094\n",
      "Epoch:  48 Loss:  102.72211456298828\n",
      "Epoch:  49 Loss:  102.05206298828125\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# Define activation functions\n",
    "def logsig(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def radbas(x):\n",
    "    return torch.exp(-torch.pow(x, 2))\n",
    "\n",
    "def purelin(x):\n",
    "    return x\n",
    "\n",
    "# Define the model\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=3, out_features=10)\n",
    "        self.fc2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.fc3 = nn.Linear(in_features=10, out_features=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = logsig(self.fc1(x))\n",
    "        x = radbas(self.fc2(x))\n",
    "        x = purelin(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Create Feed Forward NN model instance\n",
    "ffnn = FFNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(ffnn.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "ffnn_input_train, ffnn_output_train = create_train_data(rho_train_values)\n",
    "\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    ffnn_output_pred = ffnn(ffnn_input_train)\n",
    "    loss = criterion(ffnn_output_pred, ffnn_output_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch, 'Loss: ', loss.item())\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Now see how well your NN works for future state prediction for ρ = 17 and ρ = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for rho =  17 :  51.017696380615234\n",
      "Loss for rho =  35 :  119.07109832763672\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing\n",
    "# Test the model\n",
    "for rho in rho_test_values:\n",
    "    ffnn_input_test, ffnn_output_test = create_test_data(rho)\n",
    "    ffnn_output_pred = ffnn(ffnn_input_test)\n",
    "    loss = criterion(ffnn_output_pred, ffnn_output_test)\n",
    "    print('Loss for rho = ', rho, ': ', loss.item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compare feed-forward, LSTM, RNN and Echo State Networks for forecasting the dynamics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=3, hidden_layer_size=10, output_size=3):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_layer_size)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_layer_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  298.1119689941406\n",
      "Epoch:  1 Loss:  290.7731018066406\n",
      "Epoch:  2 Loss:  281.8709716796875\n",
      "Epoch:  3 Loss:  272.04144287109375\n",
      "Epoch:  4 Loss:  258.02947998046875\n",
      "Epoch:  5 Loss:  238.87533569335938\n",
      "Epoch:  6 Loss:  216.79537963867188\n",
      "Epoch:  7 Loss:  193.85147094726562\n",
      "Epoch:  8 Loss:  172.54293823242188\n",
      "Epoch:  9 Loss:  153.50540161132812\n",
      "Epoch:  10 Loss:  137.70582580566406\n",
      "Epoch:  11 Loss:  125.08660888671875\n",
      "Epoch:  12 Loss:  115.65365600585938\n",
      "Epoch:  13 Loss:  108.48930358886719\n",
      "Epoch:  14 Loss:  104.91077423095703\n",
      "Epoch:  15 Loss:  102.40277862548828\n",
      "Epoch:  16 Loss:  101.83796691894531\n",
      "Epoch:  17 Loss:  103.71575927734375\n",
      "Epoch:  18 Loss:  103.82256317138672\n",
      "Epoch:  19 Loss:  102.56806945800781\n",
      "Epoch:  20 Loss:  96.78571319580078\n",
      "Epoch:  21 Loss:  94.56050109863281\n",
      "Epoch:  22 Loss:  85.36528015136719\n",
      "Epoch:  23 Loss:  78.07530975341797\n",
      "Epoch:  24 Loss:  83.62678527832031\n",
      "Epoch:  25 Loss:  85.9566879272461\n",
      "Epoch:  26 Loss:  83.40065002441406\n",
      "Epoch:  27 Loss:  79.06675720214844\n",
      "Epoch:  28 Loss:  74.2051773071289\n",
      "Epoch:  29 Loss:  70.837158203125\n",
      "Epoch:  30 Loss:  69.02661895751953\n",
      "Epoch:  31 Loss:  68.1629409790039\n",
      "Epoch:  32 Loss:  67.62193298339844\n",
      "Epoch:  33 Loss:  66.71415710449219\n",
      "Epoch:  34 Loss:  64.9278564453125\n",
      "Epoch:  35 Loss:  71.96670532226562\n",
      "Epoch:  36 Loss:  65.48102569580078\n",
      "Epoch:  37 Loss:  63.55009460449219\n",
      "Epoch:  38 Loss:  63.05832290649414\n",
      "Epoch:  39 Loss:  62.84938430786133\n",
      "Epoch:  40 Loss:  61.58065414428711\n",
      "Epoch:  41 Loss:  61.20857620239258\n",
      "Epoch:  42 Loss:  70.12118530273438\n",
      "Epoch:  43 Loss:  61.0991096496582\n",
      "Epoch:  44 Loss:  61.129756927490234\n",
      "Epoch:  45 Loss:  61.211429595947266\n",
      "Epoch:  46 Loss:  60.70264434814453\n",
      "Epoch:  47 Loss:  60.09326171875\n",
      "Epoch:  48 Loss:  59.770721435546875\n",
      "Epoch:  49 Loss:  59.6255989074707\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "lstm = LSTM()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(lstm.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Get training data\n",
    "lstm_input_train, lstm_output_train = create_train_data(rho_train_values)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "lstm_input_train = lstm_input_train.reshape(lstm_input_train.shape[0], 1, lstm_input_train.shape[1])\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    lstm_output_pred = lstm(lstm_input_train)\n",
    "    loss = criterion(lstm_output_pred, lstm_output_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch, 'Loss: ', loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for rho =  17 :  34.123451232910156\n",
      "Loss for rho =  35 :  55.88348388671875\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "for rho in rho_test_values:\n",
    "    lstm_input_test, lstm_output_test = create_test_data(rho)\n",
    "    lstm_input_test = lstm_input_test.reshape(lstm_input_test.shape[0], 1, lstm_input_test.shape[1])\n",
    "    lstm_output_pred = lstm(lstm_input_test)\n",
    "    loss = criterion(lstm_output_pred, lstm_output_test)\n",
    "    print('Loss for rho = ', rho, ': ', loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size=3, hidden_layer_size=10, output_size=3):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_layer_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_layer_size)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.linear(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  285.5103454589844\n",
      "Epoch:  1 Loss:  264.4383850097656\n",
      "Epoch:  2 Loss:  235.49020385742188\n",
      "Epoch:  3 Loss:  198.60562133789062\n",
      "Epoch:  4 Loss:  160.79833984375\n",
      "Epoch:  5 Loss:  130.48828125\n",
      "Epoch:  6 Loss:  112.53905487060547\n",
      "Epoch:  7 Loss:  104.56169891357422\n",
      "Epoch:  8 Loss:  141.25018310546875\n",
      "Epoch:  9 Loss:  99.77456665039062\n",
      "Epoch:  10 Loss:  103.42486572265625\n",
      "Epoch:  11 Loss:  108.13023376464844\n",
      "Epoch:  12 Loss:  108.3995132446289\n",
      "Epoch:  13 Loss:  102.33721160888672\n",
      "Epoch:  14 Loss:  101.24153137207031\n",
      "Epoch:  15 Loss:  98.57857513427734\n",
      "Epoch:  16 Loss:  90.08848571777344\n",
      "Epoch:  17 Loss:  95.14173126220703\n",
      "Epoch:  18 Loss:  93.9048080444336\n",
      "Epoch:  19 Loss:  90.76856994628906\n",
      "Epoch:  20 Loss:  86.56181335449219\n",
      "Epoch:  21 Loss:  81.3731918334961\n",
      "Epoch:  22 Loss:  76.72736358642578\n",
      "Epoch:  23 Loss:  73.02940368652344\n",
      "Epoch:  24 Loss:  65.07286071777344\n",
      "Epoch:  25 Loss:  70.8486557006836\n",
      "Epoch:  26 Loss:  70.10623931884766\n",
      "Epoch:  27 Loss:  64.13890075683594\n",
      "Epoch:  28 Loss:  66.06909942626953\n",
      "Epoch:  29 Loss:  64.75978088378906\n",
      "Epoch:  30 Loss:  62.48598861694336\n",
      "Epoch:  31 Loss:  63.96604919433594\n",
      "Epoch:  32 Loss:  64.0552749633789\n",
      "Epoch:  33 Loss:  62.43747329711914\n",
      "Epoch:  34 Loss:  61.19075012207031\n",
      "Epoch:  35 Loss:  60.736209869384766\n",
      "Epoch:  36 Loss:  61.0612678527832\n",
      "Epoch:  37 Loss:  61.401920318603516\n",
      "Epoch:  38 Loss:  60.65213394165039\n",
      "Epoch:  39 Loss:  60.02488708496094\n",
      "Epoch:  40 Loss:  59.71213150024414\n",
      "Epoch:  41 Loss:  59.57294845581055\n",
      "Epoch:  42 Loss:  59.4771614074707\n",
      "Epoch:  43 Loss:  59.33243179321289\n",
      "Epoch:  44 Loss:  59.068721771240234\n",
      "Epoch:  45 Loss:  58.6885986328125\n",
      "Epoch:  46 Loss:  58.27260971069336\n",
      "Epoch:  47 Loss:  57.86370086669922\n",
      "Epoch:  48 Loss:  57.498565673828125\n",
      "Epoch:  49 Loss:  57.1705322265625\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "rnn = RNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Get training data\n",
    "rnn_input_train, rnn_output_train = create_train_data(rho_train_values)\n",
    "\n",
    "# Reshape the input data for RNN\n",
    "rnn_input_train = rnn_input_train.reshape(rnn_input_train.shape[0], 1, rnn_input_train.shape[1])\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    rnn_output_pred = rnn(rnn_input_train)\n",
    "    loss = criterion(rnn_output_pred, rnn_output_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch, 'Loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for rho =  17 :  43.22047805786133\n",
      "Loss for rho =  35 :  55.39307403564453\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "for rho in rho_test_values:\n",
    "    rnn_input_test, rnn_output_test = create_test_data(rho)\n",
    "    rnn_input_test = rnn_input_test.reshape(rnn_input_test.shape[0], 1, rnn_input_test.shape[1])\n",
    "    rnn_output_pred = rnn(rnn_input_test)\n",
    "    loss = criterion(rnn_output_pred, rnn_output_test)\n",
    "    print('Loss for rho = ', rho, ': ', loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Echo State Network (ESN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Echo State Network for Lorenz System\n",
    "class Reservoir(nn.Module):\n",
    "  def __init__(self, hidden_dim, connectivity):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.Wx = self.sparse_matrix(hidden_dim, connectivity)\n",
    "    self.Wh = self.sparse_matrix(hidden_dim, connectivity)\n",
    "    self.Uh = self.sparse_matrix(hidden_dim, connectivity)\n",
    "    self.act = nn.Tanh()\n",
    "\n",
    "  def sparse_matrix(self, m, p):\n",
    "    mask_distribution = torch.distributions.Bernoulli(p)\n",
    "    S = torch.randn((m, m))\n",
    "    mask = mask_distribution.sample(S.shape)\n",
    "    S = (S*mask).to_sparse()\n",
    "    return S\n",
    "\n",
    "  def forward(self, x, h):\n",
    "    h = self.act(torch.sparse.mm(self.Uh, h.T).T +\n",
    "                 torch.sparse.mm(self.Wh, x.T).T)\n",
    "    y = self.act(torch.sparse.mm(self.Wx, h.T).T)\n",
    "\n",
    "    return y, h\n",
    "     \n",
    "class EchoState(nn.Module):\n",
    "  def __init__(self, in_dim, out_dim, reservoir_dim, connectivity):\n",
    "    super().__init__()\n",
    "\n",
    "    self.reservoir_dim = reservoir_dim\n",
    "    self.input_to_reservoir = nn.Linear(in_dim, reservoir_dim)\n",
    "    self.input_to_reservoir.requires_grad_(False)\n",
    "\n",
    "    self.reservoir = Reservoir(reservoir_dim, connectivity)\n",
    "    self.readout = nn.Linear(reservoir_dim, out_dim)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    reservoir_in = self.input_to_reservoir(x)\n",
    "    h = torch.ones(x.size(0), self.reservoir_dim)\n",
    "    reservoirs = []\n",
    "    for i in range(x.size(1)):\n",
    "      out, h = self.reservoir(reservoir_in[:, i, :], h)\n",
    "      reservoirs.append(out.unsqueeze(1))\n",
    "    reservoirs = torch.cat(reservoirs, dim=1)\n",
    "    outputs = self.readout(reservoirs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  299.104248046875\n",
      "Epoch:  1 Loss:  245.12301635742188\n",
      "Epoch:  2 Loss:  167.2060546875\n",
      "Epoch:  3 Loss:  100.9609146118164\n",
      "Epoch:  4 Loss:  69.63018035888672\n",
      "Epoch:  5 Loss:  75.55786895751953\n",
      "Epoch:  6 Loss:  103.31529235839844\n",
      "Epoch:  7 Loss:  130.7093048095703\n",
      "Epoch:  8 Loss:  140.83364868164062\n",
      "Epoch:  9 Loss:  129.14903259277344\n",
      "Epoch:  10 Loss:  103.14781951904297\n",
      "Epoch:  11 Loss:  76.22244262695312\n",
      "Epoch:  12 Loss:  59.85285568237305\n",
      "Epoch:  13 Loss:  58.24943923950195\n",
      "Epoch:  14 Loss:  67.59815979003906\n",
      "Epoch:  15 Loss:  79.40253448486328\n",
      "Epoch:  16 Loss:  85.5162353515625\n",
      "Epoch:  17 Loss:  82.08946990966797\n",
      "Epoch:  18 Loss:  70.70177459716797\n",
      "Epoch:  19 Loss:  56.64531707763672\n",
      "Epoch:  20 Loss:  45.714744567871094\n",
      "Epoch:  21 Loss:  41.331932067871094\n",
      "Epoch:  22 Loss:  43.333168029785156\n",
      "Epoch:  23 Loss:  48.695655822753906\n",
      "Epoch:  24 Loss:  53.49345016479492\n",
      "Epoch:  25 Loss:  54.9140739440918\n",
      "Epoch:  26 Loss:  52.35865020751953\n",
      "Epoch:  27 Loss:  47.27476501464844\n",
      "Epoch:  28 Loss:  42.04713439941406\n",
      "Epoch:  29 Loss:  38.66190719604492\n",
      "Epoch:  30 Loss:  37.83060836791992\n",
      "Epoch:  31 Loss:  38.905269622802734\n",
      "Epoch:  32 Loss:  40.46986770629883\n",
      "Epoch:  33 Loss:  41.188323974609375\n",
      "Epoch:  34 Loss:  40.446571350097656\n",
      "Epoch:  35 Loss:  38.515567779541016\n",
      "Epoch:  36 Loss:  36.24766540527344\n",
      "Epoch:  37 Loss:  34.54380798339844\n",
      "Epoch:  38 Loss:  33.89545440673828\n",
      "Epoch:  39 Loss:  34.21146011352539\n",
      "Epoch:  40 Loss:  34.961761474609375\n",
      "Epoch:  41 Loss:  35.50972366333008\n",
      "Epoch:  42 Loss:  35.43685531616211\n",
      "Epoch:  43 Loss:  34.7039794921875\n",
      "Epoch:  44 Loss:  33.60089874267578\n",
      "Epoch:  45 Loss:  32.547821044921875\n",
      "Epoch:  46 Loss:  31.871553421020508\n",
      "Epoch:  47 Loss:  31.668437957763672\n",
      "Epoch:  48 Loss:  31.803321838378906\n",
      "Epoch:  49 Loss:  32.018882751464844\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "esn = EchoState(3, 3, 50, 0.1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(esn.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Get training data\n",
    "esn_input_train, esn_output_train = create_train_data(rho_train_values)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = esn(esn_input_train.view(1, -1, 3))\n",
    "    loss = criterion(outputs, esn_output_train.view(1, -1, 3))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch, 'Loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for rho =  17 :  20.919633865356445\n",
      "Loss for rho =  35 :  38.054019927978516\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "for rho in rho_test_values:\n",
    "    esn_input_test, esn_output_test = create_test_data(rho)\n",
    "    outputs = esn(esn_input_test.view(1, -1, 3))\n",
    "    loss = criterion(outputs, esn_output_test.view(1, -1, 3))\n",
    "    print('Loss for rho = ', rho, ': ', loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
